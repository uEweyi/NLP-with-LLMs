{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMe8TfdiLEzivRvXtS3IiEh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonkrohn/NLP-with-LLMs/blob/main/code/GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT\n",
        "\n",
        "In this notebook (based on [Sinan Ozdemir's](https://github.com/sinanuozdemir/oreilly-gpt-hands-on-nlg/blob/main/notebooks/Introduction_to_GPT.ipynb)), we:\n",
        "\n",
        "1. Use `transformers` pipeline objects to generate text very easily (using a GPT model)\n",
        "2. Explore tokens"
      ],
      "metadata": {
        "id": "YN46LPl-l54T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dependencies"
      ],
      "metadata": {
        "id": "x4D097ejSDzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install transformers==4.28.0"
      ],
      "metadata": {
        "id": "67O5gEnnB4V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSEmQMy09mG4"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hello, Pipeline! \n",
        "\n",
        "Let's use the `pipeline` object to generate text.\n",
        "\n",
        "Other examples of tasks we can carry out with pipelines include:\n",
        "* `\"sentiment-analysis\"`\n",
        "* `\"ner\"` (named entity recognition)\n",
        "* `\"summarization\"`\n",
        "* `\"translation_en_to_fr\"`\n",
        "* `\"feature-extraction\"`"
      ],
      "metadata": {
        "id": "9USHAIspR-lC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "generator(\"The capital of Germany is Berlin. The capital of China is Beijing. The capital of France is\",\n",
        "          max_new_tokens=2,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEB3MyurB1Ug",
        "outputId": "a76dfd9e-de01-4cd1-80be-5cb02254a679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'The capital of Germany is Berlin. The capital of China is Beijing. The capital of France is Paris.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring tokens"
      ],
      "metadata": {
        "id": "YqEJxtLiSZz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2') # load up a tokenizer"
      ],
      "metadata": {
        "id": "NgU8F2s6CfJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'love' in tokenizer.get_vocab()"
      ],
      "metadata": {
        "id": "ixSB2OeESmfd",
        "outputId": "d6be03a6-641c-48a3-98c6-edc49a733b5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'Sinan' in tokenizer.get_vocab()"
      ],
      "metadata": {
        "id": "kQGMZ-9wSjvg",
        "outputId": "a6e6725b-3a6d-4c4e-fa9d-8b4ae124b7c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode a string:"
      ],
      "metadata": {
        "id": "Ok6nimr0XWKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode('Sinan loves a beautiful day')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgHBvaBWnNFI",
        "outputId": "c4ffc510-fb43-4610-952e-cdd5dccb162d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46200, 272, 10408, 257, 4950, 1110]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "...then convert the ids into tokens: "
      ],
      "metadata": {
        "id": "0wVJdiacXcLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(tokenizer.encode('Sinan loves a beautiful day'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLWaENSZnWVQ",
        "outputId": "a4f0aedf-9c5f-40ca-e0b7-1496293451a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sin', 'an', 'Ġloves', 'Ġa', 'Ġbeautiful', 'Ġday']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(The `Ġ` character denotes a space before the token.)"
      ],
      "metadata": {
        "id": "oZYln4urXPkF"
      }
    }
  ]
}