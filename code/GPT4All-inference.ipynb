{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaAZwuEzfZNNER/4hE0Vr6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonkrohn/NLP-with-LLMs/blob/main/code/GPT4All-inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT4All CPU Interface\n",
        "\n",
        "In this notebook, we jump as quickly as we can into a command-line interaction with a GPT-4-like model that is on our own device."
      ],
      "metadata": {
        "id": "Powa-rm3ApS0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVpLf3_fX3qK",
        "outputId": "d29f8688-b49d-473e-a531-3a137c7e7807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nomic\n",
            "  Downloading nomic-1.1.6.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nomic) (8.1.3)\n",
            "Collecting jsonlines\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.9/dist-packages (from nomic) (13.3.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from nomic) (2.27.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from nomic) (1.22.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from nomic) (1.10.7)\n",
            "Collecting wonderwords\n",
            "  Downloading wonderwords-2.2.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nomic) (4.65.0)\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.3.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.9/dist-packages (from nomic) (9.0.0)\n",
            "Collecting aiohttp<4.0,>=3.0\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backoff<3.0,>=2.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->nomic) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->nomic) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->nomic) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->nomic) (2.0.12)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/dist-packages (from jsonlines->nomic) (23.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic->nomic) (4.5.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich->nomic) (2.14.0)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich->nomic) (2.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->nomic) (0.1.2)\n",
            "Building wheels for collected packages: nomic\n",
            "  Building wheel for nomic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nomic: filename=nomic-1.1.6-py3-none-any.whl size=31924 sha256=4988e50e8d78f1b95b8cc1c7e11b949567b082165831ad788a99c7eb990558c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/03/dc/3f0189b7a91ff78e15b4d0e594f2bf42f4a308ae2c1b3b712b\n",
            "Successfully built nomic\n",
            "Installing collected packages: wonderwords, multidict, loguru, jsonlines, frozenlist, backoff, async-timeout, yarl, aiosignal, aiohttp, cohere, nomic\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 backoff-2.2.1 cohere-4.3.0 frozenlist-1.3.3 jsonlines-3.1.0 loguru-0.7.0 multidict-6.0.4 nomic-1.1.6 wonderwords-2.2.0 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install nomic\n",
        "from nomic.gpt4all import GPT4All"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = GPT4All()\n",
        "m.open()"
      ],
      "metadata": {
        "id": "XZ3Rz0grAneG",
        "outputId": "892c6bb2-4557-4c16-f552-8196bbd3b638",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2023-04-27 00:01:14.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.gpt4all.gpt4all\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mDownloading executable...\u001b[0m\n",
            "51KB [00:00, 1686.61KB/s]             \n",
            "\u001b[32m2023-04-27 00:01:15.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mnomic.gpt4all.gpt4all\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[1mDownloading model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully to /root/.nomic/gpt4all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "514250KB [05:43, 1497.49KB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully to /root/.nomic/gpt4all-lora-quantized.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.prompt('What is a Large Language Model?')"
      ],
      "metadata": {
        "id": "H_Fscz0qBAAl",
        "outputId": "a2cd58c9-c919-4f8f-e55c-9d2057a3d214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A Large Language Model (LLM), also known as an external language model, refers to models that have been trained on large corpora of text data. These LLMs are typically used for tasks such as natural language processing and machine translation. They can be built using various techniques like neural networks or statistical methods depending upon the requirements.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}